{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory or zip file already exists.\n"
     ]
    }
   ],
   "source": [
    "# Set the path\n",
    "data_dir = './MMHS150K/'\n",
    "zipfile = 'MMHS150K.zip'\n",
    "download_command = f\"curl 'https://drive.usercontent.google.com/download?id=1S9mMhZFkntNnYdO-1dZXwF_8XIiFcmlF&export=download&authuser=0&confirm=t&uuid=db0e5b73-4ef4-45a4-b8f9-ef6f9c774473&at=APcmpozKaSM48fu1xNnp1-SNKDp1:1745766661322' > {zipfile}\"\n",
    "\n",
    "if not(os.path.isdir(data_dir) and os.listdir(data_dir)) and not(os.isfile(zipfile)):\n",
    "    # Directory does not exists or is empty and zip file does not exist\n",
    "    try:\n",
    "        subprocess.run(['bash', '-c', download_command], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error: {e}\")\n",
    "else:\n",
    "    print(\"Data directory or zip file already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip file \n",
    "unzip_command = f\"unzip {zipfile}\"\n",
    "if not(os.path.isdir(data_dir) and os.listdir(data_dir)) and os.isfile(zipfile):\n",
    "    # Directory does not exists or is empty and zip file does not exist\n",
    "    try:\n",
    "        subprocess.run(['bash', '-c', unzip_command], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error: {e}\")\n",
    "else:\n",
    "    print(\"Data directory or zip file already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "#json into dataframe\n",
    "df = pd.read_json(os.path.join(data_dir, 'MMHS150K_GT.json'), lines=False, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_url</th>\n",
       "      <th>labels</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>labels_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-04-28 09:09:13.714016256</th>\n",
       "      <td>http://pbs.twimg.com/tweet_video_thumb/D3gi9MH...</td>\n",
       "      <td>[4, 1, 3]</td>\n",
       "      <td>https://twitter.com/user/status/11146793537140...</td>\n",
       "      <td>@FriskDontMiss Nigga https://t.co/cAsaLWEpue</td>\n",
       "      <td>[Religion, Racist, Homophobe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-09-08 11:20:48.816660480</th>\n",
       "      <td>http://pbs.twimg.com/ext_tw_video_thumb/106301...</td>\n",
       "      <td>[5, 5, 5]</td>\n",
       "      <td>https://twitter.com/user/status/10630200488166...</td>\n",
       "      <td>My horses are retarded https://t.co/HYhqc6d5WN</td>\n",
       "      <td>[OtherHate, OtherHate, OtherHate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-20 19:22:48.075374593</th>\n",
       "      <td>http://pbs.twimg.com/media/D2OzhzHUwAADQjd.jpg</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://twitter.com/user/status/11089273680753...</td>\n",
       "      <td>“NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...</td>\n",
       "      <td>[NotHate, NotHate, NotHate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-26 23:35:34.635618305</th>\n",
       "      <td>http://pbs.twimg.com/ext_tw_video_thumb/111401...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>https://twitter.com/user/status/11145585346356...</td>\n",
       "      <td>RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...</td>\n",
       "      <td>[Racist, NotHate, NotHate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-10-22 02:08:00.215592966</th>\n",
       "      <td>http://pbs.twimg.com/media/Dl30pGIU8AAVGxO.jpg</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>https://twitter.com/user/status/10352524802155...</td>\n",
       "      <td>“EVERYbody calling you Nigger now!” https://t....</td>\n",
       "      <td>[Racist, NotHate, Racist]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         img_url  \\\n",
       "2005-04-28 09:09:13.714016256  http://pbs.twimg.com/tweet_video_thumb/D3gi9MH...   \n",
       "2003-09-08 11:20:48.816660480  http://pbs.twimg.com/ext_tw_video_thumb/106301...   \n",
       "2005-02-20 19:22:48.075374593     http://pbs.twimg.com/media/D2OzhzHUwAADQjd.jpg   \n",
       "2005-04-26 23:35:34.635618305  http://pbs.twimg.com/ext_tw_video_thumb/111401...   \n",
       "2002-10-22 02:08:00.215592966     http://pbs.twimg.com/media/Dl30pGIU8AAVGxO.jpg   \n",
       "\n",
       "                                  labels  \\\n",
       "2005-04-28 09:09:13.714016256  [4, 1, 3]   \n",
       "2003-09-08 11:20:48.816660480  [5, 5, 5]   \n",
       "2005-02-20 19:22:48.075374593  [0, 0, 0]   \n",
       "2005-04-26 23:35:34.635618305  [1, 0, 0]   \n",
       "2002-10-22 02:08:00.215592966  [1, 0, 1]   \n",
       "\n",
       "                                                                       tweet_url  \\\n",
       "2005-04-28 09:09:13.714016256  https://twitter.com/user/status/11146793537140...   \n",
       "2003-09-08 11:20:48.816660480  https://twitter.com/user/status/10630200488166...   \n",
       "2005-02-20 19:22:48.075374593  https://twitter.com/user/status/11089273680753...   \n",
       "2005-04-26 23:35:34.635618305  https://twitter.com/user/status/11145585346356...   \n",
       "2002-10-22 02:08:00.215592966  https://twitter.com/user/status/10352524802155...   \n",
       "\n",
       "                                                                      tweet_text  \\\n",
       "2005-04-28 09:09:13.714016256       @FriskDontMiss Nigga https://t.co/cAsaLWEpue   \n",
       "2003-09-08 11:20:48.816660480     My horses are retarded https://t.co/HYhqc6d5WN   \n",
       "2005-02-20 19:22:48.075374593  “NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...   \n",
       "2005-04-26 23:35:34.635618305  RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...   \n",
       "2002-10-22 02:08:00.215592966  “EVERYbody calling you Nigger now!” https://t....   \n",
       "\n",
       "                                                      labels_str  \n",
       "2005-04-28 09:09:13.714016256      [Religion, Racist, Homophobe]  \n",
       "2003-09-08 11:20:48.816660480  [OtherHate, OtherHate, OtherHate]  \n",
       "2005-02-20 19:22:48.075374593        [NotHate, NotHate, NotHate]  \n",
       "2005-04-26 23:35:34.635618305         [Racist, NotHate, NotHate]  \n",
       "2002-10-22 02:08:00.215592966          [Racist, NotHate, Racist]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"MMHS150K/MMHS150K_GT.json\", \"r\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "with open(\"MMHS150K/mmhs150k_flat.jsonl\", \"w\") as out:\n",
    "    for tweet_id, entry in raw_data.items():\n",
    "        entry[\"tweet_id\"] = tweet_id\n",
    "        out.write(json.dumps(entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f823f01180eb4223b885eb3613c6f36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "full_ds = load_dataset(\"json\", data_files=\"MMHS150K/mmhs150k_flat.jsonl\",split=\"train\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tweet_url', 'labels', 'img_url', 'tweet_text', 'labels_str', 'tweet_id'],\n",
       "    num_rows: 149823\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "# Split dataset\n",
    "def load_ids(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return set(line.strip() for line in f if line.strip())\n",
    "\n",
    "train_ids = load_ids(\"MMHS150K/splits/train_ids.txt\")\n",
    "val_ids   = load_ids(\"MMHS150K/splits/val_ids.txt\")\n",
    "test_ids  = load_ids(\"MMHS150K/splits/test_ids.txt\")\n",
    "\n",
    "train_ds = full_ds.filter(lambda ex: ex[\"tweet_id\"] in train_ids)\n",
    "val_ds   = full_ds.filter(lambda ex: ex[\"tweet_id\"] in val_ids)\n",
    "test_ds  = full_ds.filter(lambda ex: ex[\"tweet_id\"] in test_ids)\n",
    "\n",
    "mmhs150k = DatasetDict({\n",
    "    \"train\":      train_ds,\n",
    "    \"validation\": val_ds,\n",
    "    \"test\":       test_ds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tweet_url', 'labels', 'img_url', 'tweet_text', 'labels_str', 'tweet_id'],\n",
       "        num_rows: 134823\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tweet_url', 'labels', 'img_url', 'tweet_text', 'labels_str', 'tweet_id'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tweet_url', 'labels', 'img_url', 'tweet_text', 'labels_str', 'tweet_id'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmhs150k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc850f7a5f047038d7937ba7d78080f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/134823 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6e0f32c3dc45128bba5e885daaaf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baeb88307f93495284ee55585a2f8079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mmhs150k.save_to_disk(\"MMHS150K/mmhs150k_HFDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5db0b11a2c28e650914bcadf765ce81163110bd05441a302796e68891d33648"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
