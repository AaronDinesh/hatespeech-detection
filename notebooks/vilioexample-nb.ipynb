{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "guided-fleece",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 416.185294,
     "end_time": "2021-06-24T08:03:42.776300",
     "exception": false,
     "start_time": "2021-06-24T07:56:46.591006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cd ../; git clone -b master https://github.com/Muennighoff/vilio.git\n",
    "vilio_dir = './vilio/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dfeb1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/absl_py-2.2.2-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/grpcio-1.72.0-py3.12-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/termcolor-3.1.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/protobuf-6.31.0rc2-py3.12-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/yacs-0.1.8-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/tensorboard_data_server-0.7.2-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/tabulate-0.9.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/tensorboard-2.19.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/werkzeug-3.1.3-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/markdown-3.8-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/imagesize-1.4.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/facebookresearch/fvcore.git (from -r requirements.txt (line 1))\n",
      "  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-09o_71cu\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-09o_71cu\n",
      "  Resolved https://github.com/facebookresearch/fvcore.git to commit a491d5b9a06746f387aca2f1f9c7c7f28e20bef9\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.4.0 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.4.0\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/absl_py-2.2.2-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/grpcio-1.72.0-py3.12-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/termcolor-3.1.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/protobuf-6.31.0rc2-py3.12-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/yacs-0.1.8-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/tensorboard_data_server-0.7.2-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/tabulate-0.9.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/tensorboard-2.19.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/werkzeug-3.1.3-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/markdown-3.8-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/imagesize-1.4.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
      "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-jplqmll6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-jplqmll6\n",
      "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=18.0 in /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages (from pycocotools==2.0) (75.1.0)\n",
      "Collecting cython>=0.27.3 (from pycocotools==2.0)\n",
      "  Using cached Cython-3.0.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages (from pycocotools==2.0) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n",
      "Using cached Cython-3.0.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[57 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/pycocotools\n",
      "  \u001b[31m   \u001b[0m copying pycocotools/__init__.py -> build/lib.linux-x86_64-cpython-312/pycocotools\n",
      "  \u001b[31m   \u001b[0m copying pycocotools/cocoeval.py -> build/lib.linux-x86_64-cpython-312/pycocotools\n",
      "  \u001b[31m   \u001b[0m copying pycocotools/coco.py -> build/lib.linux-x86_64-cpython-312/pycocotools\n",
      "  \u001b[31m   \u001b[0m copying pycocotools/mask.py -> build/lib.linux-x86_64-cpython-312/pycocotools\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'pycocotools._mask' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-312/../common\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-312/pycocotools\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /home/alixb1908/anaconda3/envs/pyenv/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/alixb1908/anaconda3/envs/pyenv/include -fPIC -O2 -isystem /home/alixb1908/anaconda3/envs/pyenv/include -fPIC -I/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/numpy/core/include -I../common -I/home/alixb1908/anaconda3/envs/pyenv/include/python3.12 -c ../common/maskApi.c -o build/temp.linux-x86_64-cpython-312/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c: In function ‘rleDecode’:\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c:46:7: warning: this ‘for’ clause does not guard... [-Wmisleading-indentation]\n",
      "  \u001b[31m   \u001b[0m    46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
      "  \u001b[31m   \u001b[0m       |       ^~~\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c:46:49: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘for’\n",
      "  \u001b[31m   \u001b[0m    46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
      "  \u001b[31m   \u001b[0m       |                                                 ^\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c: In function ‘rleFrPoly’:\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c:166:3: warning: this ‘for’ clause does not guard... [-Wmisleading-indentation]\n",
      "  \u001b[31m   \u001b[0m   166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
      "  \u001b[31m   \u001b[0m       |   ^~~\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c:166:54: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘for’\n",
      "  \u001b[31m   \u001b[0m   166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
      "  \u001b[31m   \u001b[0m       |                                                      ^\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c:167:3: warning: this ‘for’ clause does not guard... [-Wmisleading-indentation]\n",
      "  \u001b[31m   \u001b[0m   167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
      "  \u001b[31m   \u001b[0m       |   ^~~\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c:167:54: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘for’\n",
      "  \u001b[31m   \u001b[0m   167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
      "  \u001b[31m   \u001b[0m       |                                                      ^\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c: In function ‘rleToString’:\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c:212:7: warning: this ‘if’ clause does not guard... [-Wmisleading-indentation]\n",
      "  \u001b[31m   \u001b[0m   212 |       if(more) c |= 0x20; c+=48; s[p++]=c;\n",
      "  \u001b[31m   \u001b[0m       |       ^~\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c:212:27: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘if’\n",
      "  \u001b[31m   \u001b[0m   212 |       if(more) c |= 0x20; c+=48; s[p++]=c;\n",
      "  \u001b[31m   \u001b[0m       |                           ^\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c: In function ‘rleFrString’:\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c:220:3: warning: this ‘while’ clause does not guard... [-Wmisleading-indentation]\n",
      "  \u001b[31m   \u001b[0m   220 |   while( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
      "  \u001b[31m   \u001b[0m       |   ^~~~~\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c:220:22: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘while’\n",
      "  \u001b[31m   \u001b[0m   220 |   while( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
      "  \u001b[31m   \u001b[0m       |                      ^~~~\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c:228:5: warning: this ‘if’ clause does not guard... [-Wmisleading-indentation]\n",
      "  \u001b[31m   \u001b[0m   228 |     if(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
      "  \u001b[31m   \u001b[0m       |     ^~\n",
      "  \u001b[31m   \u001b[0m ../common/maskApi.c:228:34: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘if’\n",
      "  \u001b[31m   \u001b[0m   228 |     if(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
      "  \u001b[31m   \u001b[0m       |                                  ^~~~\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /home/alixb1908/anaconda3/envs/pyenv/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/alixb1908/anaconda3/envs/pyenv/include -fPIC -O2 -isystem /home/alixb1908/anaconda3/envs/pyenv/include -fPIC -I/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/numpy/core/include -I../common -I/home/alixb1908/anaconda3/envs/pyenv/include/python3.12 -c pycocotools/_mask.c -o build/temp.linux-x86_64-cpython-312/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "  \u001b[31m   \u001b[0m cc1: fatal error: pycocotools/_mask.c: No such file or directory\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/gcc' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pycocotools\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pycocotools\n",
      "Failed to build pycocotools\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pycocotools)\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "running build\n",
      "running build_py\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2\n",
      "copying detectron2/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/config\n",
      "copying detectron2/config/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/config\n",
      "copying detectron2/config/config.py -> build/lib.linux-x86_64-cpython-312/detectron2/config\n",
      "copying detectron2/config/defaults.py -> build/lib.linux-x86_64-cpython-312/detectron2/config\n",
      "copying detectron2/config/compat.py -> build/lib.linux-x86_64-cpython-312/detectron2/config\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/structures\n",
      "copying detectron2/structures/masks.py -> build/lib.linux-x86_64-cpython-312/detectron2/structures\n",
      "copying detectron2/structures/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/structures\n",
      "copying detectron2/structures/instances.py -> build/lib.linux-x86_64-cpython-312/detectron2/structures\n",
      "copying detectron2/structures/image_list.py -> build/lib.linux-x86_64-cpython-312/detectron2/structures\n",
      "copying detectron2/structures/rotated_boxes.py -> build/lib.linux-x86_64-cpython-312/detectron2/structures\n",
      "copying detectron2/structures/boxes.py -> build/lib.linux-x86_64-cpython-312/detectron2/structures\n",
      "copying detectron2/structures/keypoints.py -> build/lib.linux-x86_64-cpython-312/detectron2/structures\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/checkpoint\n",
      "copying detectron2/checkpoint/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/checkpoint\n",
      "copying detectron2/checkpoint/c2_model_loading.py -> build/lib.linux-x86_64-cpython-312/detectron2/checkpoint\n",
      "copying detectron2/checkpoint/catalog.py -> build/lib.linux-x86_64-cpython-312/detectron2/checkpoint\n",
      "copying detectron2/checkpoint/detection_checkpoint.py -> build/lib.linux-x86_64-cpython-312/detectron2/checkpoint\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/layers\n",
      "copying detectron2/layers/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/layers\n",
      "copying detectron2/layers/batch_norm.py -> build/lib.linux-x86_64-cpython-312/detectron2/layers\n",
      "copying detectron2/layers/shape_spec.py -> build/lib.linux-x86_64-cpython-312/detectron2/layers\n",
      "copying detectron2/layers/roi_align_rotated.py -> build/lib.linux-x86_64-cpython-312/detectron2/layers\n",
      "copying detectron2/layers/deform_conv.py -> build/lib.linux-x86_64-cpython-312/detectron2/layers\n",
      "copying detectron2/layers/wrappers.py -> build/lib.linux-x86_64-cpython-312/detectron2/layers\n",
      "copying detectron2/layers/nms.py -> build/lib.linux-x86_64-cpython-312/detectron2/layers\n",
      "copying detectron2/layers/rotated_boxes.py -> build/lib.linux-x86_64-cpython-312/detectron2/layers\n",
      "copying detectron2/layers/roi_align.py -> build/lib.linux-x86_64-cpython-312/detectron2/layers\n",
      "copying detectron2/layers/mask_ops.py -> build/lib.linux-x86_64-cpython-312/detectron2/layers\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/engine\n",
      "copying detectron2/engine/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/engine\n",
      "copying detectron2/engine/launch.py -> build/lib.linux-x86_64-cpython-312/detectron2/engine\n",
      "copying detectron2/engine/hooks.py -> build/lib.linux-x86_64-cpython-312/detectron2/engine\n",
      "copying detectron2/engine/train_loop.py -> build/lib.linux-x86_64-cpython-312/detectron2/engine\n",
      "copying detectron2/engine/defaults.py -> build/lib.linux-x86_64-cpython-312/detectron2/engine\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "copying detectron2/utils/serialize.py -> build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "copying detectron2/utils/collect_env.py -> build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "copying detectron2/utils/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "copying detectron2/utils/memory.py -> build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "copying detectron2/utils/video_visualizer.py -> build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "copying detectron2/utils/colormap.py -> build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "copying detectron2/utils/logger.py -> build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "copying detectron2/utils/events.py -> build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "copying detectron2/utils/env.py -> build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "copying detectron2/utils/comm.py -> build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "copying detectron2/utils/registry.py -> build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "copying detectron2/utils/visualizer.py -> build/lib.linux-x86_64-cpython-312/detectron2/utils\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo\n",
      "copying detectron2/model_zoo/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo\n",
      "copying detectron2/model_zoo/model_zoo.py -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/evaluation\n",
      "copying detectron2/evaluation/testing.py -> build/lib.linux-x86_64-cpython-312/detectron2/evaluation\n",
      "copying detectron2/evaluation/sem_seg_evaluation.py -> build/lib.linux-x86_64-cpython-312/detectron2/evaluation\n",
      "copying detectron2/evaluation/coco_evaluation.py -> build/lib.linux-x86_64-cpython-312/detectron2/evaluation\n",
      "copying detectron2/evaluation/lvis_evaluation.py -> build/lib.linux-x86_64-cpython-312/detectron2/evaluation\n",
      "copying detectron2/evaluation/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/evaluation\n",
      "copying detectron2/evaluation/panoptic_evaluation.py -> build/lib.linux-x86_64-cpython-312/detectron2/evaluation\n",
      "copying detectron2/evaluation/pascal_voc_evaluation.py -> build/lib.linux-x86_64-cpython-312/detectron2/evaluation\n",
      "copying detectron2/evaluation/evaluator.py -> build/lib.linux-x86_64-cpython-312/detectron2/evaluation\n",
      "copying detectron2/evaluation/cityscapes_evaluation.py -> build/lib.linux-x86_64-cpython-312/detectron2/evaluation\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/modeling\n",
      "copying detectron2/modeling/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling\n",
      "copying detectron2/modeling/box_regression.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling\n",
      "copying detectron2/modeling/anchor_generator.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling\n",
      "copying detectron2/modeling/postprocessing.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling\n",
      "copying detectron2/modeling/matcher.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling\n",
      "copying detectron2/modeling/poolers.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling\n",
      "copying detectron2/modeling/test_time_augmentation.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling\n",
      "copying detectron2/modeling/sampling.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/solver\n",
      "copying detectron2/solver/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/solver\n",
      "copying detectron2/solver/lr_scheduler.py -> build/lib.linux-x86_64-cpython-312/detectron2/solver\n",
      "copying detectron2/solver/build.py -> build/lib.linux-x86_64-cpython-312/detectron2/solver\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/data\n",
      "copying detectron2/data/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/data\n",
      "copying detectron2/data/dataset_mapper.py -> build/lib.linux-x86_64-cpython-312/detectron2/data\n",
      "copying detectron2/data/detection_utils.py -> build/lib.linux-x86_64-cpython-312/detectron2/data\n",
      "copying detectron2/data/build.py -> build/lib.linux-x86_64-cpython-312/detectron2/data\n",
      "copying detectron2/data/catalog.py -> build/lib.linux-x86_64-cpython-312/detectron2/data\n",
      "copying detectron2/data/common.py -> build/lib.linux-x86_64-cpython-312/detectron2/data\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/modeling/backbone\n",
      "copying detectron2/modeling/backbone/backbone.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/backbone\n",
      "copying detectron2/modeling/backbone/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/backbone\n",
      "copying detectron2/modeling/backbone/resnet.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/backbone\n",
      "copying detectron2/modeling/backbone/build.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/backbone\n",
      "copying detectron2/modeling/backbone/fpn.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/backbone\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/modeling/meta_arch\n",
      "copying detectron2/modeling/meta_arch/rcnn.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/meta_arch\n",
      "copying detectron2/modeling/meta_arch/panoptic_fpn.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/meta_arch\n",
      "copying detectron2/modeling/meta_arch/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/meta_arch\n",
      "copying detectron2/modeling/meta_arch/semantic_seg.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/meta_arch\n",
      "copying detectron2/modeling/meta_arch/build.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/meta_arch\n",
      "copying detectron2/modeling/meta_arch/retinanet.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/meta_arch\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/modeling/proposal_generator\n",
      "copying detectron2/modeling/proposal_generator/rrpn.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/proposal_generator\n",
      "copying detectron2/modeling/proposal_generator/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/proposal_generator\n",
      "copying detectron2/modeling/proposal_generator/build.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/proposal_generator\n",
      "copying detectron2/modeling/proposal_generator/rpn_outputs.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/proposal_generator\n",
      "copying detectron2/modeling/proposal_generator/rpn.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/proposal_generator\n",
      "copying detectron2/modeling/proposal_generator/rrpn_outputs.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/proposal_generator\n",
      "copying detectron2/modeling/proposal_generator/proposal_utils.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/proposal_generator\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/modeling/roi_heads\n",
      "copying detectron2/modeling/roi_heads/rotated_fast_rcnn.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/roi_heads\n",
      "copying detectron2/modeling/roi_heads/roi_heads.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/roi_heads\n",
      "copying detectron2/modeling/roi_heads/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/roi_heads\n",
      "copying detectron2/modeling/roi_heads/mask_head.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/roi_heads\n",
      "copying detectron2/modeling/roi_heads/cascade_rcnn.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/roi_heads\n",
      "copying detectron2/modeling/roi_heads/fast_rcnn.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/roi_heads\n",
      "copying detectron2/modeling/roi_heads/box_head.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/roi_heads\n",
      "copying detectron2/modeling/roi_heads/keypoint_head.py -> build/lib.linux-x86_64-cpython-312/detectron2/modeling/roi_heads\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/data/transforms\n",
      "copying detectron2/data/transforms/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/transforms\n",
      "copying detectron2/data/transforms/transform.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/transforms\n",
      "copying detectron2/data/transforms/transform_gen.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/transforms\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/data/samplers\n",
      "copying detectron2/data/samplers/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/samplers\n",
      "copying detectron2/data/samplers/distributed_sampler.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/samplers\n",
      "copying detectron2/data/samplers/grouped_batch_sampler.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/samplers\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/data/datasets\n",
      "copying detectron2/data/datasets/__init__.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/datasets\n",
      "copying detectron2/data/datasets/register_coco.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/datasets\n",
      "copying detectron2/data/datasets/coco.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/datasets\n",
      "copying detectron2/data/datasets/lvis.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/datasets\n",
      "copying detectron2/data/datasets/lvis_v0_5_categories.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/datasets\n",
      "copying detectron2/data/datasets/builtin_meta.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/datasets\n",
      "copying detectron2/data/datasets/pascal_voc.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/datasets\n",
      "copying detectron2/data/datasets/builtin.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/datasets\n",
      "copying detectron2/data/datasets/cityscapes.py -> build/lib.linux-x86_64-cpython-312/detectron2/data/datasets\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs\n",
      "copying detectron2/model_zoo/configs/Base-RCNN-DilatedC5.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs\n",
      "copying detectron2/model_zoo/configs/Base-RCNN-C4.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs\n",
      "copying detectron2/model_zoo/configs/Base-RCNN-FPN.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs\n",
      "copying detectron2/model_zoo/configs/Base-RetinaNet.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Detectron1-Comparisons\n",
      "copying detectron2/model_zoo/configs/Detectron1-Comparisons/mask_rcnn_R_50_FPN_noaug_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Detectron1-Comparisons\n",
      "copying detectron2/model_zoo/configs/Detectron1-Comparisons/faster_rcnn_R_50_FPN_noaug_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Detectron1-Comparisons\n",
      "copying detectron2/model_zoo/configs/Detectron1-Comparisons/keypoint_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Detectron1-Comparisons\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/PascalVOC-Detection\n",
      "copying detectron2/model_zoo/configs/PascalVOC-Detection/faster_rcnn_R_50_FPN.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/PascalVOC-Detection\n",
      "copying detectron2/model_zoo/configs/PascalVOC-Detection/faster_rcnn_R_50_C4.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/PascalVOC-Detection\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/VG-Detection\n",
      "copying detectron2/model_zoo/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/VG-Detection\n",
      "copying detectron2/model_zoo/configs/VG-Detection/faster_rcnn_R_101_C4_caffe.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/VG-Detection\n",
      "copying detectron2/model_zoo/configs/VG-Detection/faster_rcnn_R_101_C4_caffemaxpool.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/VG-Detection\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_C4_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/rpn_R_50_C4_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_DC5_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_C4_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/rpn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/fast_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_C4_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_DC5_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Detection\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Misc\n",
      "copying detectron2/model_zoo/configs/Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Misc\n",
      "copying detectron2/model_zoo/configs/Misc/panoptic_fpn_R_101_dconv_cascade_gn_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Misc\n",
      "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_3x_gn.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Misc\n",
      "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_1x_cls_agnostic.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Misc\n",
      "copying detectron2/model_zoo/configs/Misc/semantic_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Misc\n",
      "copying detectron2/model_zoo/configs/Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Misc\n",
      "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Misc\n",
      "copying detectron2/model_zoo/configs/Misc/scratch_mask_rcnn_R_50_FPN_3x_gn.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Misc\n",
      "copying detectron2/model_zoo/configs/Misc/cascade_mask_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Misc\n",
      "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_1x_dconv_c3-c5.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Misc\n",
      "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_3x_syncbn.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Misc\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/LVIS-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/LVIS-InstanceSegmentation/mask_rcnn_R_101_FPN_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/LVIS-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/LVIS-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/LVIS-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/LVIS-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/LVIS-InstanceSegmentation\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_training_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_training_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_normalized_training_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/panoptic_fpn_R_50_inference_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/rpn_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/semantic_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/rpn_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/panoptic_fpn_R_50_instant_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/retinanet_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/semantic_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/fast_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_inference_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/semantic_R_50_FPN_training_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/retinanet_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_instant_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_training_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/fast_rcnn_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/panoptic_fpn_R_50_training_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_DC5_inference_acc_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/quick_schedules\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Keypoints\n",
      "copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Keypoints\n",
      "copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Keypoints\n",
      "copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_X_101_32x8d_FPN_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Keypoints\n",
      "copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Keypoints\n",
      "copying detectron2/model_zoo/configs/COCO-Keypoints/Base-Keypoint-RCNN-FPN.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-Keypoints\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_C4_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_DC5_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/Base-Panoptic-FPN.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
      "copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_1x.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
      "creating build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Cityscapes\n",
      "copying detectron2/model_zoo/configs/Cityscapes/mask_rcnn_R_50_FPN.yaml -> build/lib.linux-x86_64-cpython-312/detectron2/model_zoo/configs/Cityscapes\n",
      "running build_ext\n",
      "/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:576: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n",
      "building 'detectron2._C' extension\n",
      "creating build/temp.linux-x86_64-cpython-312/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign\n",
      "creating build/temp.linux-x86_64-cpython-312/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated\n",
      "creating build/temp.linux-x86_64-cpython-312/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated\n",
      "creating build/temp.linux-x86_64-cpython-312/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated\n",
      "g++ -pthread -B /home/alixb1908/anaconda3/envs/pyenv/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/alixb1908/anaconda3/envs/pyenv/include -fPIC -O2 -isystem /home/alixb1908/anaconda3/envs/pyenv/include -fPIC -I/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include -I/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/home/alixb1908/anaconda3/envs/pyenv/include/python3.12 -c /home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp -o build/temp.linux-x86_64-cpython-312/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "In file included from \u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor detectron2::ROIAlign_forward(const at::Tensor&, const at::Tensor&, float, int, int, int, bool)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign.h:62:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   62 |   if (\u001b[01;35m\u001b[Kinput.type()\u001b[m\u001b[K.is_cuda()) {\n",
      "      |       \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/TensorUtils.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor detectron2::ROIAlign_backward(const at::Tensor&, const at::Tensor&, float, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign.h:98:16:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   98 |   if (\u001b[01;35m\u001b[Kgrad.type()\u001b[m\u001b[K.is_cuda()) {\n",
      "      |       \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/TensorUtils.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:429:49:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  429 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\u001b[01;35m\u001b[Kinput.type()\u001b[m\u001b[K, \"ROIAlign_forward\", [&] {\n",
      "      |                                       \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/Dispatch.h:195:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
      "  195 |     const auto& the_type = \u001b[01;36m\u001b[KTYPE\u001b[m\u001b[K;                                            \\\n",
      "      |                            \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:429:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
      "  429 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
      "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/TensorUtils.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/Dispatch.h:198:48:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kcannot convert ‘\u001b[01m\u001b[Kconst at::DeprecatedTypeProperties\u001b[m\u001b[K’ to ‘\u001b[01m\u001b[Kc10::ScalarType\u001b[m\u001b[K’\n",
      "  198 |     at::ScalarType _st = ::detail::scalar_type(\u001b[01;31m\u001b[Kthe_type\u001b[m\u001b[K);                   \\\n",
      "      |                                                \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "      |                                                \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                                \u001b[01;31m\u001b[Kconst at::DeprecatedTypeProperties\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/Dispatch.h:226:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
      "  226 |   \u001b[01;36m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K(                                        \\\n",
      "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:429:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
      "  429 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
      "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/Dispatch.h:100:50:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 1 of ‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(c10::ScalarType)\u001b[m\u001b[K’\n",
      "  100 | inline at::ScalarType scalar_type(\u001b[01;36m\u001b[Kat::ScalarType s\u001b[m\u001b[K) {\n",
      "      |                                   \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:481:48:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  481 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\u001b[01;35m\u001b[Kgrad.type()\u001b[m\u001b[K, \"ROIAlign_forward\", [&] {\n",
      "      |                                       \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/Dispatch.h:195:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
      "  195 |     const auto& the_type = \u001b[01;36m\u001b[KTYPE\u001b[m\u001b[K;                                            \\\n",
      "      |                            \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:481:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
      "  481 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K(grad.type(), \"ROIAlign_forward\", [&] {\n",
      "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/TensorUtils.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/Dispatch.h:198:48:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kcannot convert ‘\u001b[01m\u001b[Kconst at::DeprecatedTypeProperties\u001b[m\u001b[K’ to ‘\u001b[01m\u001b[Kc10::ScalarType\u001b[m\u001b[K’\n",
      "  198 |     at::ScalarType _st = ::detail::scalar_type(\u001b[01;31m\u001b[Kthe_type\u001b[m\u001b[K);                   \\\n",
      "      |                                                \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "      |                                                \u001b[01;31m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                                \u001b[01;31m\u001b[Kconst at::DeprecatedTypeProperties\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/Dispatch.h:226:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
      "  226 |   \u001b[01;36m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K(                                        \\\n",
      "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:481:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
      "  481 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K(grad.type(), \"ROIAlign_forward\", [&] {\n",
      "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/home/alixb1908/anaconda3/envs/pyenv/lib/python3.12/site-packages/torch/include/ATen/Dispatch.h:100:50:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K  initializing argument 1 of ‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(c10::ScalarType)\u001b[m\u001b[K’\n",
      "  100 | inline at::ScalarType scalar_type(\u001b[01;36m\u001b[Kat::ScalarType s\u001b[m\u001b[K) {\n",
      "      |                                   \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~^\u001b[m\u001b[K\n",
      "error: command '/usr/bin/g++' failed with exit code 1\n"
     ]
    }
   ],
   "source": [
    "!cd {vilio_dir}py-bottom-up-attention; pip install -r requirements.txt\n",
    "%pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "!cd {vilio_dir}py-bottom-up-attention; python setup.py build develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alternative-static",
   "metadata": {
    "papermill": {
     "duration": 19.625386,
     "end_time": "2021-06-24T08:04:02.867466",
     "exception": false,
     "start_time": "2021-06-24T08:03:43.242080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2_mscoco_proposal_maxnms.py\", line 16, in <module>\n",
      "    import cv2\n",
      "ModuleNotFoundError: No module named 'cv2'\n"
     ]
    }
   ],
   "source": [
    "!cp -r ./MMHS150K/img_resized/ {vilio_dir}py*/data/\n",
    "%pip install opencv-python\n",
    "%pip install fvcore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a60540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2_mscoco_proposal_maxnms.py\", line 22, in <module>\n",
      "    from detectron2.engine import DefaultPredictor\n",
      "  File \"/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/engine/__init__.py\", line 11, in <module>\n",
      "    from .hooks import *\n",
      "  File \"/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/engine/hooks.py\", line 17, in <module>\n",
      "    from detectron2.evaluation.testing import flatten_results_dict\n",
      "  File \"/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/evaluation/__init__.py\", line 2, in <module>\n",
      "    from .cityscapes_evaluation import CityscapesEvaluator\n",
      "  File \"/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/evaluation/cityscapes_evaluation.py\", line 10, in <module>\n",
      "    from detectron2.data import MetadataCatalog\n",
      "  File \"/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/data/__init__.py\", line 4, in <module>\n",
      "    from .build import (\n",
      "  File \"/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/data/build.py\", line 13, in <module>\n",
      "    from detectron2.structures import BoxMode\n",
      "  File \"/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/structures/__init__.py\", line 2, in <module>\n",
      "    from .boxes import Boxes, BoxMode, pairwise_iou\n",
      "  File \"/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/structures/boxes.py\", line 8, in <module>\n",
      "    from detectron2.layers import cat\n",
      "  File \"/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/__init__.py\", line 3, in <module>\n",
      "    from .deform_conv import DeformConv, ModulatedDeformConv\n",
      "  File \"/home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/layers/deform_conv.py\", line 10, in <module>\n",
      "    from detectron2 import _C\n",
      "ImportError: /home/alixb1908/Documents/Project_Repos_EPFL/hatespeech-detection/vilio/py-bottom-up-attention/detectron2/_C.cpython-312-x86_64-linux-gnu.so: undefined symbol: _ZN3c106detail14torchCheckFailEPKcS2_jRKSs\n"
     ]
    }
   ],
   "source": [
    "# %pip install torchvision\n",
    "!cd {vilio_dir}py-bottom-up-attention; python detectron2_mscoco_proposal_maxnms.py --batchsize 1 --split img --weight vgattr \\\n",
    "--minboxes 36 --maxboxes 36\n",
    "# !cd {vilio_dir}py*/data; ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19729bd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4140713313.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    setup.py clean --all\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "closing-blowing",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-24T08:04:03.878253Z",
     "iopub.status.busy": "2021-06-24T08:04:03.877322Z",
     "iopub.status.idle": "2021-06-24T08:04:03.881840Z",
     "shell.execute_reply": "2021-06-24T08:04:03.882429Z",
     "shell.execute_reply.started": "2021-06-23T19:25:00.517461Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.51451,
     "end_time": "2021-06-24T08:04:03.882634",
     "exception": false,
     "start_time": "2021-06-24T08:04:03.368124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing new_req.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile new_req.txt\n",
    "sacremoses==0.0.43\n",
    "pandas==1.1.3\n",
    "regex==2020.4.4\n",
    "h5py==2.10.0\n",
    "filelock==3.0.10\n",
    "scipy==1.4.1\n",
    "sentencepiece~=0.1.91\n",
    "matplotlib==3.2.1\n",
    "torch==1.6.0\n",
    "tensorflow==2.3.1\n",
    "tqdm==4.45.0\n",
    "numpy==1.18.1\n",
    "six==1.14.0\n",
    "packaging==20.1\n",
    "wandb==0.10.8\n",
    "psutil==5.7.0\n",
    "requests==2.23.0\n",
    "pytorch_lightning==1.0.4\n",
    "ImageHash==4.1.0\n",
    "tokenizers~=0.9.2\n",
    "transformers==3.5.1 # Required due to some imports in the files under src/vilio/transformers\n",
    "torchvision==0.7.0\n",
    "jieba==0.42.1\n",
    "botocore==1.19.8\n",
    "spacy==2.3.2\n",
    "boto3==1.16.8\n",
    "comet_ml==3.2.5\n",
    "dataclasses==0.6\n",
    "fairseq==0.9.0\n",
    "ftfy==5.8\n",
    "fugashi==1.0.5\n",
    "ipadic==1.0.0\n",
    "lmdb==1.0.0\n",
    "Pillow==8.0.1\n",
    "py3nvml==0.2.6\n",
    "pydantic==1.7.2\n",
    "pythainlp==2.2.4\n",
    "PyYAML==5.3.1\n",
    "scikit_learn==0.23.2\n",
    "tensorboardX==2.1\n",
    "timeout_decorator==0.4.1\n",
    "torchcontrib==0.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weighted-rider",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-24T08:04:04.881785Z",
     "iopub.status.busy": "2021-06-24T08:04:04.880762Z",
     "iopub.status.idle": "2021-06-24T08:08:53.036680Z",
     "shell.execute_reply": "2021-06-24T08:08:53.035462Z",
     "shell.execute_reply.started": "2021-06-23T19:25:00.547347Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 288.658515,
     "end_time": "2021-06-24T08:08:53.036884",
     "exception": false,
     "start_time": "2021-06-24T08:04:04.378369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses==0.0.43\r\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 883 kB 906 kB/s \r\n",
      "\u001b[?25hCollecting pandas==1.1.3\r\n",
      "  Downloading pandas-1.1.3-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 6.2 MB/s \r\n",
      "\u001b[?25hCollecting regex==2020.4.4\r\n",
      "  Downloading regex-2020.4.4-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 679 kB 12.7 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /opt/conda/lib/python3.7/site-packages (from -r new_req.txt (line 4)) (2.10.0)\r\n",
      "Collecting filelock==3.0.10\r\n",
      "  Downloading filelock-3.0.10-py3-none-any.whl (7.3 kB)\r\n",
      "Collecting scipy==1.4.1\r\n",
      "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 26.1 MB 139 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece~=0.1.91 in /opt/conda/lib/python3.7/site-packages (from -r new_req.txt (line 7)) (0.1.95)\r\n",
      "Collecting matplotlib==3.2.1\r\n",
      "  Downloading matplotlib-3.2.1-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 35.1 MB/s \r\n",
      "\u001b[?25hCollecting torch==1.6.0\r\n",
      "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 748.8 MB 12 kB/s \r\n",
      "\u001b[?25hCollecting tensorflow==2.3.1\r\n",
      "  Downloading tensorflow-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 320.4 MB 17 kB/s \r\n",
      "\u001b[?25hCollecting tqdm==4.45.0\r\n",
      "  Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 60 kB 3.0 MB/s \r\n",
      "\u001b[?25hCollecting numpy==1.18.1\r\n",
      "  Downloading numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 32.2 MB/s \r\n",
      "\u001b[?25hCollecting six==1.14.0\r\n",
      "  Downloading six-1.14.0-py2.py3-none-any.whl (10 kB)\r\n",
      "Collecting packaging==20.1\r\n",
      "  Downloading packaging-20.1-py2.py3-none-any.whl (36 kB)\r\n",
      "Collecting wandb==0.10.8\r\n",
      "  Downloading wandb-0.10.8-py2.py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 22.2 MB/s \r\n",
      "\u001b[?25hCollecting psutil==5.7.0\r\n",
      "  Downloading psutil-5.7.0.tar.gz (449 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 449 kB 37.2 MB/s \r\n",
      "\u001b[?25hCollecting requests==2.23.0\r\n",
      "  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 58 kB 3.5 MB/s \r\n",
      "\u001b[?25hCollecting pytorch_lightning==1.0.4\r\n",
      "  Downloading pytorch_lightning-1.0.4-py3-none-any.whl (554 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 554 kB 23.7 MB/s \r\n",
      "\u001b[?25hCollecting ImageHash==4.1.0\r\n",
      "  Downloading ImageHash-4.1.0.tar.gz (291 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 291 kB 34.4 MB/s \r\n",
      "\u001b[?25hCollecting tokenizers~=0.9.2\r\n",
      "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 30.8 MB/s \r\n",
      "\u001b[?25hCollecting transformers==3.5.1\r\n",
      "  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 30.8 MB/s \r\n",
      "\u001b[?25hCollecting torchvision==0.7.0\r\n",
      "  Downloading torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 23.5 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: jieba==0.42.1 in /opt/conda/lib/python3.7/site-packages (from -r new_req.txt (line 23)) (0.42.1)\r\n",
      "Collecting botocore==1.19.8\r\n",
      "  Downloading botocore-1.19.8-py2.py3-none-any.whl (6.7 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 31.5 MB/s \r\n",
      "\u001b[?25hCollecting spacy==2.3.2\r\n",
      "  Downloading spacy-2.3.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 24.1 MB/s \r\n",
      "\u001b[?25hCollecting boto3==1.16.8\r\n",
      "  Downloading boto3-1.16.8-py2.py3-none-any.whl (129 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 129 kB 33.9 MB/s \r\n",
      "\u001b[?25hCollecting comet_ml==3.2.5\r\n",
      "  Downloading comet_ml-3.2.5-py2.py3-none-any.whl (227 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 227 kB 33.2 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: dataclasses==0.6 in /opt/conda/lib/python3.7/site-packages (from -r new_req.txt (line 28)) (0.6)\r\n",
      "Collecting fairseq==0.9.0\r\n",
      "  Downloading fairseq-0.9.0.tar.gz (306 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 306 kB 33.3 MB/s \r\n",
      "\u001b[?25hCollecting ftfy==5.8\r\n",
      "  Downloading ftfy-5.8.tar.gz (64 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 64 kB 1.3 MB/s \r\n",
      "\u001b[?25hCollecting fugashi==1.0.5\r\n",
      "  Downloading fugashi-1.0.5-cp37-cp37m-manylinux1_x86_64.whl (477 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 477 kB 29.4 MB/s \r\n",
      "\u001b[?25hCollecting ipadic==1.0.0\r\n",
      "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 13.4 MB 24.9 MB/s \r\n",
      "\u001b[?25hCollecting lmdb==1.0.0\r\n",
      "  Downloading lmdb-1.0.0-cp37-cp37m-manylinux1_x86_64.whl (280 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 280 kB 24.9 MB/s \r\n",
      "\u001b[?25hCollecting Pillow==8.0.1\r\n",
      "  Downloading Pillow-8.0.1-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 21.8 MB/s \r\n",
      "\u001b[?25hCollecting py3nvml==0.2.6\r\n",
      "  Downloading py3nvml-0.2.6-py3-none-any.whl (55 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 55 kB 2.1 MB/s \r\n",
      "\u001b[?25hCollecting pydantic==1.7.2\r\n",
      "  Downloading pydantic-1.7.2-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 9.1 MB 25.2 MB/s \r\n",
      "\u001b[?25hCollecting pythainlp==2.2.4\r\n",
      "  Downloading pythainlp-2.2.4-py3-none-any.whl (8.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 8.9 MB 22.7 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: PyYAML==5.3.1 in /opt/conda/lib/python3.7/site-packages (from -r new_req.txt (line 38)) (5.3.1)\r\n",
      "Collecting scikit_learn==0.23.2\r\n",
      "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 8.1 MB/s \r\n",
      "\u001b[?25hCollecting tensorboardX==2.1\r\n",
      "  Downloading tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 308 kB 8.4 MB/s \r\n",
      "\u001b[?25hCollecting timeout_decorator==0.4.1\r\n",
      "  Downloading timeout-decorator-0.4.1.tar.gz (4.8 kB)\r\n",
      "Collecting torchcontrib==0.0.2\r\n",
      "  Downloading torchcontrib-0.0.2.tar.gz (11 kB)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3==1.16.8->-r new_req.txt (line 26)) (0.10.0)\r\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3==1.16.8->-r new_req.txt (line 26)) (0.3.7)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore==1.19.8->-r new_req.txt (line 24)) (2.8.1)\r\n",
      "Collecting urllib3<1.26,>=1.25.4\r\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 127 kB 31.2 MB/s \r\n",
      "\u001b[?25hCollecting dulwich>=0.20.6\r\n",
      "  Downloading dulwich-0.20.23-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (529 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 529 kB 23.2 MB/s \r\n",
      "\u001b[?25hCollecting wurlitzer>=1.0.2\r\n",
      "  Downloading wurlitzer-2.1.0-py2.py3-none-any.whl (6.2 kB)\r\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /opt/conda/lib/python3.7/site-packages (from comet_ml==3.2.5->-r new_req.txt (line 27)) (7.352.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /opt/conda/lib/python3.7/site-packages (from comet_ml==3.2.5->-r new_req.txt (line 27)) (1.12.1)\r\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from comet_ml==3.2.5->-r new_req.txt (line 27)) (3.2.0)\r\n",
      "Requirement already satisfied: websocket-client>=0.55.0 in /opt/conda/lib/python3.7/site-packages (from comet_ml==3.2.5->-r new_req.txt (line 27)) (0.57.0)\r\n",
      "Collecting netifaces>=0.10.7\r\n",
      "  Downloading netifaces-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (32 kB)\r\n",
      "Collecting everett[ini]>=1.0.1\r\n",
      "  Downloading everett-1.0.3-py2.py3-none-any.whl (31 kB)\r\n",
      "Requirement already satisfied: cffi in /opt/conda/lib/python3.7/site-packages (from fairseq==0.9.0->-r new_req.txt (line 29)) (1.14.5)\r\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from fairseq==0.9.0->-r new_req.txt (line 29)) (0.29.23)\r\n",
      "Collecting sacrebleu\r\n",
      "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 54 kB 1.7 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from ftfy==5.8->-r new_req.txt (line 30)) (0.2.5)\r\n",
      "Requirement already satisfied: PyWavelets in /opt/conda/lib/python3.7/site-packages (from ImageHash==4.1.0->-r new_req.txt (line 19)) (1.1.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.1->-r new_req.txt (line 8)) (1.3.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.1->-r new_req.txt (line 8)) (2.4.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.1->-r new_req.txt (line 8)) (0.10.0)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas==1.1.3->-r new_req.txt (line 2)) (2021.1)\r\n",
      "Collecting xmltodict\r\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\r\n",
      "Collecting tinydb>=3.0\r\n",
      "  Downloading tinydb-4.4.0-py3-none-any.whl (21 kB)\r\n",
      "Collecting python-crfsuite>=0.9.6\r\n",
      "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 743 kB 21.3 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (0.18.2)\r\n",
      "Requirement already satisfied: fsspec>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (0.8.7)\r\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (2.4.1)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests==2.23.0->-r new_req.txt (line 17)) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests==2.23.0->-r new_req.txt (line 17)) (2020.12.5)\r\n",
      "Collecting chardet<4,>=3.0.2\r\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 133 kB 34.0 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses==0.0.43->-r new_req.txt (line 1)) (7.1.2)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses==0.0.43->-r new_req.txt (line 1)) (1.0.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn==0.23.2->-r new_req.txt (line 39)) (2.1.0)\r\n",
      "Collecting thinc==7.4.1\r\n",
      "  Downloading thinc-7.4.1-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 19.0 MB/s \r\n",
      "\u001b[?25hCollecting blis<0.5.0,>=0.4.0\r\n",
      "  Downloading blis-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 22.1 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.2->-r new_req.txt (line 25)) (1.0.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.2->-r new_req.txt (line 25)) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.2->-r new_req.txt (line 25)) (1.0.5)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.2->-r new_req.txt (line 25)) (0.8.2)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.2->-r new_req.txt (line 25)) (3.0.5)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.2->-r new_req.txt (line 25)) (1.1.3)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.2->-r new_req.txt (line 25)) (1.0.5)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.2->-r new_req.txt (line 25)) (2.0.5)\r\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorboardX==2.1->-r new_req.txt (line 40)) (3.15.8)\r\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.1->-r new_req.txt (line 10)) (0.3.3)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.1->-r new_req.txt (line 10)) (0.36.2)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.1->-r new_req.txt (line 10)) (1.1.0)\r\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.1->-r new_req.txt (line 10)) (1.1.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.1->-r new_req.txt (line 10)) (3.3.0)\r\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.1->-r new_req.txt (line 10)) (1.6.3)\r\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.1->-r new_req.txt (line 10)) (0.12.0)\r\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\r\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 459 kB 34.0 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.1->-r new_req.txt (line 10)) (1.32.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.1->-r new_req.txt (line 10)) (0.2.0)\r\n",
      "Collecting tokenizers~=0.9.2\r\n",
      "  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 32.4 MB/s \r\n",
      "\u001b[?25hCollecting sentencepiece~=0.1.91\r\n",
      "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 22.1 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb==0.10.8->-r new_req.txt (line 15)) (3.5.4)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb==0.10.8->-r new_req.txt (line 15)) (0.4.0)\r\n",
      "Collecting watchdog>=0.8.3\r\n",
      "  Downloading watchdog-2.1.2-py3-none-manylinux2014_x86_64.whl (74 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 74 kB 2.2 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: sentry-sdk>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb==0.10.8->-r new_req.txt (line 15)) (1.0.0)\r\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb==0.10.8->-r new_req.txt (line 15)) (1.0.1)\r\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb==0.10.8->-r new_req.txt (line 15)) (2.3)\r\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb==0.10.8->-r new_req.txt (line 15)) (5.0.2)\r\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb==0.10.8->-r new_req.txt (line 15)) (3.1.14)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.2->-r new_req.txt (line 25)) (3.4.0)\r\n",
      "Collecting configobj\r\n",
      "  Downloading configobj-5.0.6.tar.gz (33 kB)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb==0.10.8->-r new_req.txt (line 15)) (4.0.7)\r\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.10.8->-r new_req.txt (line 15)) (3.0.5)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.2->-r new_req.txt (line 25)) (3.4.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.2->-r new_req.txt (line 25)) (3.7.4.3)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml==3.2.5->-r new_req.txt (line 27)) (0.17.3)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml==3.2.5->-r new_req.txt (line 27)) (20.3.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (3.3.4)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (1.8.0)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (1.26.1)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (1.0.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (0.4.3)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (4.7.2)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (4.2.1)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (1.3.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.0.4->-r new_req.txt (line 18)) (3.0.1)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi->fairseq==0.9.0->-r new_req.txt (line 29)) (2.20)\r\n",
      "Collecting portalocker==2.0.0\r\n",
      "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Building wheels for collected packages: fairseq, ftfy, ImageHash, ipadic, psutil, sacremoses, timeout-decorator, torchcontrib, configobj\r\n",
      "  Building wheel for fairseq (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.9.0-cp37-cp37m-linux_x86_64.whl size=2008266 sha256=75cd9d6e714dacb6eac81fabcd5b0ae6047e17c8843c5b9e03888c2f48e7f95f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6b/27/e2/c55614da7eb71041bb08f02e8a302b869e51185eb7c575a604\r\n",
      "  Building wheel for ftfy (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for ftfy: filename=ftfy-5.8-py3-none-any.whl size=45613 sha256=11f27adaae52c3b8bf0e9fefff6926c71a2989e4dee9c254d1419b33906668ff\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/49/1c/fc/8b19700f939810cd8fd9495ae34934b246279791288eda1c31\r\n",
      "  Building wheel for ImageHash (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for ImageHash: filename=ImageHash-4.1.0-py2.py3-none-any.whl size=291991 sha256=999f8a99d81bea29ee7cba6f38ed8c0cd6f10ab25602ccb73d316e3f530c71c8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/72/b0/e5be34699908d9ff25dcb3debbb717987b766af61bbddffdfe\r\n",
      "  Building wheel for ipadic (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556723 sha256=5ad20e9a52ad919062426d04bba3aad05e18da7a3e834f68cab2a5b403aa0309\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/33/8b/99/cf0d27191876637cd3639a560f93aa982d7855ce826c94348b\r\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.7.0-cp37-cp37m-linux_x86_64.whl size=276509 sha256=ca43353aec818493f61b7532abc59b49bf378ee7e83ca8e6ffc4994ec140e001\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b6/e7/50/aee9cc966163d74430f13f208171dee22f11efa4a4a826661c\r\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893258 sha256=e64d0b507e445b856ac53b57187694dd81b6faeed53cf4047523cd10ce40096d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\r\n",
      "  Building wheel for timeout-decorator (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for timeout-decorator: filename=timeout_decorator-0.4.1-py3-none-any.whl size=5015 sha256=6c3898e2b11f8004b99c0ca2cb9d9de9af4f8278a0e911c34f126bd5fa764313\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/a0/87/83fe34960f698558661b71ce991c84a0fd4cb10c56f22eaaa1\r\n",
      "  Building wheel for torchcontrib (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-py3-none-any.whl size=7533 sha256=7b9144c193e8ac6b67f2a68c1aadb63c761263066315eb124e29a0f07137e827\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/91/58/d0/f03811c3e34e1f14031294b5f30d8693689972af874d1225b8\r\n",
      "  Building wheel for configobj (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for configobj: filename=configobj-5.0.6-py3-none-any.whl size=34547 sha256=88f8ab37972576ca4389e31d09f3d7e92b8847a54834a090d1b768495a3410df\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/c4/19/13d74440f2a571841db6b6e0a273694327498884dafb9cf978\r\n",
      "Successfully built fairseq ftfy ImageHash ipadic psutil sacremoses timeout-decorator torchcontrib configobj\r\n",
      "Installing collected packages: urllib3, chardet, six, requests, numpy, tqdm, regex, portalocker, everett, configobj, botocore, blis, xmltodict, wurlitzer, watchdog, torch, tokenizers, tinydb, thinc, tensorflow-estimator, sentencepiece, scipy, sacremoses, sacrebleu, python-crfsuite, psutil, Pillow, packaging, netifaces, filelock, dulwich, wandb, transformers, torchvision, torchcontrib, timeout-decorator, tensorflow, tensorboardX, spacy, scikit-learn, pytorch-lightning, pythainlp, pydantic, py3nvml, pandas, matplotlib, lmdb, ipadic, ImageHash, fugashi, ftfy, fairseq, comet-ml, boto3\r\n",
      "  Attempting uninstall: urllib3\r\n",
      "    Found existing installation: urllib3 1.26.4\r\n",
      "    Uninstalling urllib3-1.26.4:\r\n",
      "      Successfully uninstalled urllib3-1.26.4\r\n",
      "  Attempting uninstall: chardet\r\n",
      "    Found existing installation: chardet 4.0.0\r\n",
      "    Uninstalling chardet-4.0.0:\r\n",
      "      Successfully uninstalled chardet-4.0.0\r\n",
      "  Attempting uninstall: six\r\n",
      "    Found existing installation: six 1.15.0\r\n",
      "    Uninstalling six-1.15.0:\r\n",
      "      Successfully uninstalled six-1.15.0\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.25.1\r\n",
      "    Uninstalling requests-2.25.1:\r\n",
      "      Successfully uninstalled requests-2.25.1\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.19.5\r\n",
      "    Uninstalling numpy-1.19.5:\r\n",
      "      Successfully uninstalled numpy-1.19.5\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.59.0\r\n",
      "    Uninstalling tqdm-4.59.0:\r\n",
      "      Successfully uninstalled tqdm-4.59.0\r\n",
      "  Attempting uninstall: regex\r\n",
      "    Found existing installation: regex 2021.3.17\r\n",
      "    Uninstalling regex-2021.3.17:\r\n",
      "      Successfully uninstalled regex-2021.3.17\r\n",
      "  Attempting uninstall: portalocker\r\n",
      "    Found existing installation: portalocker 2.3.0\r\n",
      "    Uninstalling portalocker-2.3.0:\r\n",
      "      Successfully uninstalled portalocker-2.3.0\r\n",
      "  Attempting uninstall: botocore\r\n",
      "    Found existing installation: botocore 1.20.53\r\n",
      "    Uninstalling botocore-1.20.53:\r\n",
      "      Successfully uninstalled botocore-1.20.53\r\n",
      "  Attempting uninstall: blis\r\n",
      "    Found existing installation: blis 0.7.4\r\n",
      "    Uninstalling blis-0.7.4:\r\n",
      "      Successfully uninstalled blis-0.7.4\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.4.0\r\n",
      "    Uninstalling torch-1.4.0:\r\n",
      "      Successfully uninstalled torch-1.4.0\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.10.2\r\n",
      "    Uninstalling tokenizers-0.10.2:\r\n",
      "      Successfully uninstalled tokenizers-0.10.2\r\n",
      "  Attempting uninstall: thinc\r\n",
      "    Found existing installation: thinc 7.4.5\r\n",
      "    Uninstalling thinc-7.4.5:\r\n",
      "      Successfully uninstalled thinc-7.4.5\r\n",
      "  Attempting uninstall: tensorflow-estimator\r\n",
      "    Found existing installation: tensorflow-estimator 2.4.0\r\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\r\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\r\n",
      "  Attempting uninstall: sentencepiece\r\n",
      "    Found existing installation: sentencepiece 0.1.95\r\n",
      "    Uninstalling sentencepiece-0.1.95:\r\n",
      "      Successfully uninstalled sentencepiece-0.1.95\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.5.4\r\n",
      "    Uninstalling scipy-1.5.4:\r\n",
      "      Successfully uninstalled scipy-1.5.4\r\n",
      "  Attempting uninstall: sacremoses\r\n",
      "    Found existing installation: sacremoses 0.0.45\r\n",
      "    Uninstalling sacremoses-0.0.45:\r\n",
      "      Successfully uninstalled sacremoses-0.0.45\r\n",
      "  Attempting uninstall: psutil\r\n",
      "    Found existing installation: psutil 5.8.0\r\n",
      "    Uninstalling psutil-5.8.0:\r\n",
      "      Successfully uninstalled psutil-5.8.0\r\n",
      "  Attempting uninstall: Pillow\r\n",
      "    Found existing installation: Pillow 7.2.0\r\n",
      "    Uninstalling Pillow-7.2.0:\r\n",
      "      Successfully uninstalled Pillow-7.2.0\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 20.9\r\n",
      "    Uninstalling packaging-20.9:\r\n",
      "      Successfully uninstalled packaging-20.9\r\n",
      "  Attempting uninstall: filelock\r\n",
      "    Found existing installation: filelock 3.0.12\r\n",
      "    Uninstalling filelock-3.0.12:\r\n",
      "      Successfully uninstalled filelock-3.0.12\r\n",
      "  Attempting uninstall: wandb\r\n",
      "    Found existing installation: wandb 0.10.26\r\n",
      "    Uninstalling wandb-0.10.26:\r\n",
      "      Successfully uninstalled wandb-0.10.26\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.5.1\r\n",
      "    Uninstalling transformers-4.5.1:\r\n",
      "      Successfully uninstalled transformers-4.5.1\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.5.0\r\n",
      "    Uninstalling torchvision-0.5.0:\r\n",
      "      Successfully uninstalled torchvision-0.5.0\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.4.1\r\n",
      "    Uninstalling tensorflow-2.4.1:\r\n",
      "      Successfully uninstalled tensorflow-2.4.1\r\n",
      "  Attempting uninstall: tensorboardX\r\n",
      "    Found existing installation: tensorboardX 2.2\r\n",
      "    Uninstalling tensorboardX-2.2:\r\n",
      "      Successfully uninstalled tensorboardX-2.2\r\n",
      "  Attempting uninstall: spacy\r\n",
      "    Found existing installation: spacy 2.3.5\r\n",
      "    Uninstalling spacy-2.3.5:\r\n",
      "      Successfully uninstalled spacy-2.3.5\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 0.24.1\r\n",
      "    Uninstalling scikit-learn-0.24.1:\r\n",
      "      Successfully uninstalled scikit-learn-0.24.1\r\n",
      "  Attempting uninstall: pytorch-lightning\r\n",
      "    Found existing installation: pytorch-lightning 1.2.8\r\n",
      "    Uninstalling pytorch-lightning-1.2.8:\r\n",
      "      Successfully uninstalled pytorch-lightning-1.2.8\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 1.1.5\r\n",
      "    Uninstalling pandas-1.1.5:\r\n",
      "      Successfully uninstalled pandas-1.1.5\r\n",
      "  Attempting uninstall: matplotlib\r\n",
      "    Found existing installation: matplotlib 3.4.1\r\n",
      "    Uninstalling matplotlib-3.4.1:\r\n",
      "      Successfully uninstalled matplotlib-3.4.1\r\n",
      "  Attempting uninstall: lmdb\r\n",
      "    Found existing installation: lmdb 1.2.0\r\n",
      "    Uninstalling lmdb-1.2.0:\r\n",
      "      Successfully uninstalled lmdb-1.2.0\r\n",
      "  Attempting uninstall: ImageHash\r\n",
      "    Found existing installation: ImageHash 4.2.0\r\n",
      "    Uninstalling ImageHash-4.2.0:\r\n",
      "      Successfully uninstalled ImageHash-4.2.0\r\n",
      "  Attempting uninstall: boto3\r\n",
      "    Found existing installation: boto3 1.17.53\r\n",
      "    Uninstalling boto3-1.17.53:\r\n",
      "      Successfully uninstalled boto3-1.17.53\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "stumpy 1.8.0 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\r\n",
      "sklearn-pandas 2.1.0 requires pandas>=1.1.4, but you have pandas 1.1.3 which is incompatible.\r\n",
      "sklearn-pandas 2.1.0 requires scipy>=1.5.1, but you have scipy 1.4.1 which is incompatible.\r\n",
      "pyldavis 3.3.1 requires numpy>=1.20.0, but you have numpy 1.18.1 which is incompatible.\r\n",
      "pyldavis 3.3.1 requires pandas>=1.2.0, but you have pandas 1.1.3 which is incompatible.\r\n",
      "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.18.1 which is incompatible.\r\n",
      "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\r\n",
      "phik 0.11.2 requires scipy>=1.5.2, but you have scipy 1.4.1 which is incompatible.\r\n",
      "pdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.2.1 which is incompatible.\r\n",
      "pandas-profiling 2.11.0 requires requests>=2.24.0, but you have requests 2.23.0 which is incompatible.\r\n",
      "pandas-profiling 2.11.0 requires tqdm>=4.48.2, but you have tqdm 4.45.0 which is incompatible.\r\n",
      "osmnx 1.0.1 requires matplotlib>=3.3, but you have matplotlib 3.2.1 which is incompatible.\r\n",
      "osmnx 1.0.1 requires numpy>=1.19, but you have numpy 1.18.1 which is incompatible.\r\n",
      "osmnx 1.0.1 requires requests>=2.25, but you have requests 2.23.0 which is incompatible.\r\n",
      "matrixprofile 1.1.10 requires protobuf==3.11.2, but you have protobuf 3.15.8 which is incompatible.\r\n",
      "jupyterlab-git 0.11.0 requires nbdime<2.0.0,>=1.1.0, but you have nbdime 2.1.0 which is incompatible.\r\n",
      "imbalanced-learn 0.8.0 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\r\n",
      "gym 0.18.0 requires Pillow<=7.2.0, but you have pillow 8.0.1 which is incompatible.\r\n",
      "fastai 2.3.0 requires torch<1.8,>=1.7.0, but you have torch 1.6.0 which is incompatible.\r\n",
      "fastai 2.3.0 requires torchvision<0.9,>=0.8, but you have torchvision 0.7.0 which is incompatible.\r\n",
      "earthengine-api 0.1.261 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\r\n",
      "autogluon-core 0.1.0 requires numpy==1.19.5, but you have numpy 1.18.1 which is incompatible.\r\n",
      "autogluon-core 0.1.0 requires scipy==1.5.4, but you have scipy 1.4.1 which is incompatible.\r\n",
      "allennlp 2.3.0 requires torchvision<0.10.0,>=0.8.1, but you have torchvision 0.7.0 which is incompatible.\r\n",
      "allennlp 2.3.0 requires transformers<4.6,>=4.1, but you have transformers 3.5.1 which is incompatible.\r\n",
      "aiobotocore 1.3.0 requires botocore<1.20.50,>=1.20.49, but you have botocore 1.19.8 which is incompatible.\u001b[0m\r\n",
      "Successfully installed ImageHash-4.1.0 Pillow-8.0.1 blis-0.4.1 boto3-1.16.8 botocore-1.19.8 chardet-3.0.4 comet-ml-3.2.5 configobj-5.0.6 dulwich-0.20.23 everett-1.0.3 fairseq-0.9.0 filelock-3.0.10 ftfy-5.8 fugashi-1.0.5 ipadic-1.0.0 lmdb-1.0.0 matplotlib-3.2.1 netifaces-0.11.0 numpy-1.18.1 packaging-20.1 pandas-1.1.3 portalocker-2.0.0 psutil-5.7.0 py3nvml-0.2.6 pydantic-1.7.2 pythainlp-2.2.4 python-crfsuite-0.9.7 pytorch-lightning-1.0.4 regex-2020.4.4 requests-2.23.0 sacrebleu-1.5.1 sacremoses-0.0.43 scikit-learn-0.23.2 scipy-1.4.1 sentencepiece-0.1.91 six-1.14.0 spacy-2.3.2 tensorboardX-2.1 tensorflow-2.3.1 tensorflow-estimator-2.3.0 thinc-7.4.1 timeout-decorator-0.4.1 tinydb-4.4.0 tokenizers-0.9.3 torch-1.6.0 torchcontrib-0.0.2 torchvision-0.7.0 tqdm-4.45.0 transformers-3.5.1 urllib3-1.25.11 wandb-0.10.8 watchdog-2.1.2 wurlitzer-2.1.0 xmltodict-0.12.0\r\n"
     ]
    }
   ],
   "source": [
    "%pip install -r new_req.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "medium-conjunction",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-24T08:08:55.899102Z",
     "iopub.status.busy": "2021-06-24T08:08:55.898027Z",
     "iopub.status.idle": "2021-06-24T08:08:57.449881Z",
     "shell.execute_reply": "2021-06-24T08:08:57.448151Z",
     "shell.execute_reply.started": "2021-06-23T19:28:29.376795Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 2.86228,
     "end_time": "2021-06-24T08:08:57.450052",
     "exception": false,
     "start_time": "2021-06-24T08:08:54.587772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp ../vilio/py*/data/example.jsonl ../vilio/data/\n",
    "!cp ../vilio/py*/data/hm_vgattr3636.tsv ../vilio/data/HM_img.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spoken-characteristic",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-24T08:09:00.255006Z",
     "iopub.status.busy": "2021-06-24T08:09:00.249127Z",
     "iopub.status.idle": "2021-06-24T08:09:01.025088Z",
     "shell.execute_reply": "2021-06-24T08:09:01.024475Z",
     "shell.execute_reply.started": "2021-06-23T19:28:30.734016Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 2.280236,
     "end_time": "2021-06-24T08:09:01.025238",
     "exception": false,
     "start_time": "2021-06-24T08:08:58.745002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  new_req.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sized-handling",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-24T08:09:03.674214Z",
     "iopub.status.busy": "2021-06-24T08:09:03.672794Z",
     "iopub.status.idle": "2021-06-24T08:09:03.679280Z",
     "shell.execute_reply": "2021-06-24T08:09:03.680201Z",
     "shell.execute_reply.started": "2021-06-23T19:34:15.855295Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 1.350065,
     "end_time": "2021-06-24T08:09:03.680431",
     "exception": false,
     "start_time": "2021-06-24T08:09:02.330366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../vilio/hm_inf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../vilio/hm_inf.py\n",
    "import collections\n",
    "import os\n",
    "\n",
    "from param import args\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "if args.tsv:\n",
    "    from fts_tsv.hm_data_tsv import HMTorchDataset, HMEvaluator, HMDataset\n",
    "else:\n",
    "    from fts_lmdb.hm_data import HMTorchDataset, HMEvaluator, HMDataset\n",
    "\n",
    "from src.vilio.transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "from utils.pandas_scripts import clean_data\n",
    "\n",
    "from entryU import ModelU\n",
    "from entryX import ModelX\n",
    "from entryV import ModelV\n",
    "from entryD import ModelD\n",
    "from entryO import ModelO\n",
    "\n",
    "# Two different SWA Methods - https://pytorch.org/blog/pytorch-1.6-now-includes-stochastic-weight-averaging/\n",
    "if args.swa:\n",
    "    from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "    from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "if args.contrib:\n",
    "    from torchcontrib.optim import SWA\n",
    "\n",
    "\n",
    "# Largely sticking to standards set in LXMERT here\n",
    "DataTuple = collections.namedtuple(\"DataTuple\", 'dataset loader evaluator')\n",
    "\n",
    "def get_tuple(splits: str, bs:int, shuffle=False, drop_last=False) -> DataTuple:\n",
    "\n",
    "    dset =  HMDataset(splits)\n",
    "\n",
    "    tset = HMTorchDataset(splits)\n",
    "    evaluator = HMEvaluator(tset)\n",
    "    data_loader = DataLoader(\n",
    "        tset, batch_size=bs,\n",
    "        shuffle=shuffle, num_workers=args.num_workers,\n",
    "        drop_last=drop_last, pin_memory=True\n",
    "    )\n",
    "\n",
    "    return DataTuple(dataset=dset, loader=data_loader, evaluator=evaluator)\n",
    "\n",
    "class HM:\n",
    "    def __init__(self):\n",
    "        \n",
    "        if args.train is not None:\n",
    "            self.train_tuple = get_tuple(\n",
    "                args.train, bs=args.batch_size, shuffle=True, drop_last=False\n",
    "            )\n",
    "\n",
    "        if args.valid is not None:\n",
    "            valid_bsize = 2048 if args.multiGPU else 50\n",
    "            self.valid_tuple = get_tuple(\n",
    "                args.valid, bs=valid_bsize,\n",
    "                shuffle=False, drop_last=False\n",
    "            )\n",
    "        else:\n",
    "            self.valid_tuple = None\n",
    "\n",
    "        # Select Model, X is default\n",
    "        if args.model == \"X\":\n",
    "            self.model = ModelX(args)\n",
    "        elif args.model == \"V\":\n",
    "            self.model = ModelV(args)\n",
    "        elif args.model == \"U\":\n",
    "            self.model = ModelU(args)\n",
    "        elif args.model == \"D\":\n",
    "            self.model = ModelD(args)\n",
    "        elif args.model == 'O':\n",
    "            self.model = ModelO(args)\n",
    "        else:\n",
    "            print(args.model, \" is not implemented.\")\n",
    "\n",
    "        # Load pre-trained weights from paths\n",
    "        if args.loadpre is not None:\n",
    "            self.model.load(args.loadpre)\n",
    "\n",
    "        # GPU options\n",
    "        if args.multiGPU:\n",
    "            self.model.lxrt_encoder.multi_gpu()\n",
    "\n",
    "        self.model = self.model.cuda()\n",
    "\n",
    "        # Losses and optimizer\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.nllloss = nn.NLLLoss()\n",
    "\n",
    "        if args.train is not None:\n",
    "            batch_per_epoch = len(self.train_tuple.loader)\n",
    "            self.t_total = int(batch_per_epoch * args.epochs // args.acc)\n",
    "            print(\"Total Iters: %d\" % self.t_total)\n",
    "\n",
    "        def is_backbone(n):\n",
    "            if \"encoder\" in n:\n",
    "                return True\n",
    "            elif \"embeddings\" in n:\n",
    "                return True\n",
    "            elif \"pooler\" in n:\n",
    "                return True\n",
    "            print(\"F: \", n)\n",
    "            return False\n",
    "\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "        params = list(self.model.named_parameters())\n",
    "        if args.reg:\n",
    "            optimizer_grouped_parameters = [\n",
    "                {\"params\": [p for n, p in params if is_backbone(n)], \"lr\": args.lr},\n",
    "                {\"params\": [p for n, p in params if not is_backbone(n)], \"lr\": args.lr * 500},\n",
    "            ]\n",
    "\n",
    "            for n, p in self.model.named_parameters():\n",
    "                print(n)\n",
    "\n",
    "            self.optim = AdamW(optimizer_grouped_parameters, lr=args.lr)\n",
    "        else:\n",
    "            optimizer_grouped_parameters = [\n",
    "                {'params': [p for n, p in params if not any(nd in n for nd in no_decay)], 'weight_decay': args.wd},\n",
    "                {'params': [p for n, p in params if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "                ]\n",
    "\n",
    "            self.optim = AdamW(optimizer_grouped_parameters, lr=args.lr)\n",
    "\n",
    "        if args.train is not None:\n",
    "            self.scheduler = get_linear_schedule_with_warmup(self.optim, self.t_total * 0.1, self.t_total)\n",
    "        \n",
    "        self.output = args.output\n",
    "        os.makedirs(self.output, exist_ok=True)\n",
    "\n",
    "        # SWA Method:\n",
    "        if args.contrib:\n",
    "            self.optim = SWA(self.optim, swa_start=self.t_total * 0.75, swa_freq=5, swa_lr=args.lr)\n",
    "\n",
    "        if args.swa: \n",
    "            self.swa_model = AveragedModel(self.model)\n",
    "            self.swa_start = self.t_total * 0.75\n",
    "            self.swa_scheduler = SWALR(self.optim, swa_lr=args.lr)\n",
    "\n",
    "    def train(self, train_tuple, eval_tuple):\n",
    "\n",
    "        dset, loader, evaluator = train_tuple\n",
    "        iter_wrapper = (lambda x: tqdm(x, total=len(loader))) if args.tqdm else (lambda x: x)\n",
    "\n",
    "        print(\"Batches:\", len(loader))\n",
    "\n",
    "        self.optim.zero_grad()\n",
    "\n",
    "        best_roc = 0.\n",
    "        ups = 0\n",
    "        \n",
    "        total_loss = 0.\n",
    "\n",
    "        for epoch in range(args.epochs):\n",
    "            \n",
    "            if args.reg:\n",
    "                if args.model != \"X\":\n",
    "                    print(self.model.model.layer_weights)\n",
    "\n",
    "            id2ans = {}\n",
    "            id2prob = {}\n",
    "\n",
    "            for i, (ids, feats, boxes, sent, target) in iter_wrapper(enumerate(loader)):\n",
    "\n",
    "                if ups == args.midsave:\n",
    "                    self.save(\"MID\")\n",
    "\n",
    "                self.model.train()\n",
    "\n",
    "                if args.swa:\n",
    "                    self.swa_model.train()\n",
    "                \n",
    "                feats, boxes, target = feats.cuda(), boxes.cuda(), target.long().cuda()\n",
    "\n",
    "                # Model expects visual feats as tuple of feats & boxes\n",
    "                logit = self.model(sent, (feats, boxes))\n",
    "\n",
    "                # Note: LogSoftmax does not change order, hence there should be nothing wrong with taking it as our prediction \n",
    "                # In fact ROC AUC stays the exact same for logsoftmax / normal softmax, but logsoftmax is better for loss calculation\n",
    "                # due to stronger penalization & decomplexifying properties (log(a/b) = log(a) - log(b))\n",
    "                logit = self.logsoftmax(logit)\n",
    "                score = logit[:, 1]\n",
    "\n",
    "                if i < 1:\n",
    "                    print(logit[0, :].detach())\n",
    "               \n",
    "                # Note: This loss is the same as CrossEntropy (We splitted it up in logsoftmax & neg. log likelihood loss)\n",
    "                loss = self.nllloss(logit.view(-1, 2), target.view(-1))\n",
    "\n",
    "                # Scaling loss by batch size, as we have batches with different sizes, since we do not \"drop_last\" & dividing by acc for accumulation\n",
    "                # Not scaling the loss will worsen performance by ~2abs%\n",
    "                loss = loss * logit.size(0) / args.acc\n",
    "                loss.backward()\n",
    "\n",
    "                total_loss += loss.detach().item()\n",
    "\n",
    "                # Acts as argmax - extracting the higher score & the corresponding index (0 or 1)\n",
    "                _, predict = logit.detach().max(1)\n",
    "                # Getting labels for accuracy\n",
    "                for qid, l in zip(ids, predict.cpu().numpy()):\n",
    "                    id2ans[qid] = l\n",
    "                # Getting probabilities for Roc auc\n",
    "                for qid, l in zip(ids, score.detach().cpu().numpy()):\n",
    "                    id2prob[qid] = l\n",
    "\n",
    "                if (i+1) % args.acc == 0:\n",
    "\n",
    "                    nn.utils.clip_grad_norm_(self.model.parameters(), args.clip)\n",
    "\n",
    "                    self.optim.step()\n",
    "\n",
    "                    if (args.swa) and (ups > self.swa_start):\n",
    "                        self.swa_model.update_parameters(self.model)\n",
    "                        self.swa_scheduler.step()\n",
    "                    else:\n",
    "                        self.scheduler.step()\n",
    "                    self.optim.zero_grad()\n",
    "\n",
    "                    ups += 1\n",
    "\n",
    "                    # Do Validation in between\n",
    "                    if ups % 250 == 0: \n",
    "                        \n",
    "                        log_str = \"\\nEpoch(U) %d(%d): Train AC %0.2f RA %0.4f LOSS %0.4f\\n\" % (epoch, ups, evaluator.evaluate(id2ans)*100, \n",
    "                        evaluator.roc_auc(id2prob)*100, total_loss)\n",
    "\n",
    "                        # Set loss back to 0 after printing it\n",
    "                        total_loss = 0.\n",
    "\n",
    "                        if self.valid_tuple is not None:  # Do Validation\n",
    "                            acc, roc_auc = self.evaluate(eval_tuple)\n",
    "                            if roc_auc > best_roc:\n",
    "                                best_roc = roc_auc\n",
    "                                best_acc = acc\n",
    "                                # Only save BEST when no midsave is specified to save space\n",
    "                                #if args.midsave < 0:\n",
    "                                #    self.save(\"BEST\")\n",
    "\n",
    "                            log_str += \"\\nEpoch(U) %d(%d): DEV AC %0.2f RA %0.4f \\n\" % (epoch, ups, acc*100.,roc_auc*100)\n",
    "                            log_str += \"Epoch(U) %d(%d): BEST AC %0.2f RA %0.4f \\n\" % (epoch, ups, best_acc*100., best_roc*100.)\n",
    "    \n",
    "                        print(log_str, end='')\n",
    "\n",
    "                        with open(self.output + \"/log.log\", 'a') as f:\n",
    "                            f.write(log_str)\n",
    "                            f.flush()\n",
    "\n",
    "        if (epoch + 1) == args.epochs:\n",
    "            if args.contrib:\n",
    "                self.optim.swap_swa_sgd()\n",
    "\n",
    "        self.save(\"LAST\" + args.train)\n",
    "\n",
    "    def predict(self, eval_tuple: DataTuple, dump=None, out_csv=True):\n",
    "\n",
    "        dset, loader, evaluator = eval_tuple\n",
    "        id2ans = {}\n",
    "        id2prob = {}\n",
    "\n",
    "        for i, datum_tuple in enumerate(loader):\n",
    "\n",
    "            ids, feats, boxes, sent = datum_tuple[:4]\n",
    "\n",
    "            self.model.eval()\n",
    "\n",
    "            if args.swa:\n",
    "                self.swa_model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                feats, boxes = feats.cuda(), boxes.cuda()\n",
    "                logit = self.model(sent, (feats, boxes))\n",
    "\n",
    "                # Note: LogSoftmax does not change order, hence there should be nothing wrong with taking it as our prediction\n",
    "                logit = self.logsoftmax(logit)\n",
    "                score = logit[:, 1]\n",
    "\n",
    "                if args.swa:\n",
    "                    logit = self.swa_model(sent, (feats, boxes))\n",
    "                    logit = self.logsoftmax(logit)\n",
    "\n",
    "                _, predict = logit.max(1)\n",
    "\n",
    "                for qid, l in zip(ids, predict.cpu().numpy()):\n",
    "                    id2ans[qid] = l\n",
    "\n",
    "                # Getting probas for Roc Auc\n",
    "                for qid, l in zip(ids, score.cpu().numpy()):\n",
    "                    id2prob[qid] = l\n",
    "\n",
    "        if dump is not None:\n",
    "            if out_csv == True:\n",
    "                evaluator.dump_csv(id2ans, id2prob, dump)\n",
    "            else:\n",
    "                evaluator.dump_result(id2ans, dump)\n",
    "\n",
    "        return id2ans, id2prob\n",
    "\n",
    "    def evaluate(self, eval_tuple: DataTuple, dump=None):\n",
    "        \"\"\"Evaluate all data in data_tuple.\"\"\"\n",
    "        id2ans, id2prob = self.predict(eval_tuple, dump=dump)\n",
    "\n",
    "        acc = eval_tuple.evaluator.evaluate(id2ans)\n",
    "        roc_auc = eval_tuple.evaluator.roc_auc(id2prob)\n",
    "\n",
    "        return acc, roc_auc\n",
    "\n",
    "    def save(self, name):\n",
    "        if args.swa:\n",
    "            torch.save(self.swa_model.state_dict(),\n",
    "                    os.path.join(self.output, \"%s.pth\" % name))\n",
    "        else:\n",
    "            torch.save(self.model.state_dict(),\n",
    "                    os.path.join(self.output, \"%s.pth\" % name))\n",
    "\n",
    "    def load(self, path):\n",
    "        print(\"Load model from %s\" % path)\n",
    "            \n",
    "        state_dict = torch.load(\"%s\" % path)\n",
    "        new_state_dict = {}\n",
    "        for key, value in state_dict.items():\n",
    "            # N_averaged is a key in SWA models we cannot load, so we skip it\n",
    "            if key.startswith(\"n_averaged\"):\n",
    "                print(\"n_averaged:\", value)\n",
    "                continue\n",
    "            # SWA Models will start with module\n",
    "            if key.startswith(\"module.\"):\n",
    "                new_state_dict[key[len(\"module.\"):]] = value\n",
    "            else:\n",
    "                new_state_dict[key] = value\n",
    "        state_dict = new_state_dict\n",
    "        self.model.load_state_dict(state_dict)\n",
    "\n",
    "def main():\n",
    "    # Build Class\n",
    "    hm = HM()\n",
    "\n",
    "    # Load Model\n",
    "    if args.loadfin is not None:\n",
    "        hm.load(args.loadfin)\n",
    "\n",
    "    # Train and/or Test:\n",
    "    if args.train is not None:\n",
    "        print('Splits in Train data:', hm.train_tuple.dataset.splits)\n",
    "        if hm.valid_tuple is not None:\n",
    "            print('Splits in Valid data:', hm.valid_tuple.dataset.splits)\n",
    "        else:\n",
    "            print(\"DO NOT USE VALIDATION\")\n",
    "        hm.train(hm.train_tuple, hm.valid_tuple)\n",
    "\n",
    "        # If we also test afterwards load the last model\n",
    "        if args.test is not None:\n",
    "            hm.load(os.path.join(hm.output, \"LAST\" + args.train + \".pth\"))\n",
    "\n",
    "    if args.test is not None:\n",
    "        # We can specify multiple test args e.g. test,test_unseen\n",
    "        for split in args.test.split(\",\"):\n",
    "            # Anthing that has no labels:\n",
    "            if 'test' in split:\n",
    "                hm.predict(\n",
    "                    get_tuple(split, bs=args.batch_size,\n",
    "                            shuffle=False, drop_last=False),\n",
    "                    dump=os.path.join(args.output, '{}_{}.csv'.format(args.exp, split))\n",
    "                )\n",
    "            # Anything else that has labels:\n",
    "            elif 'dev' in split or 'valid' in split or 'train' in split:\n",
    "                result = hm.evaluate(\n",
    "                    get_tuple(split, bs=args.batch_size,\n",
    "                            shuffle=False, drop_last=False),\n",
    "                    dump=os.path.join(args.output, '{}_{}.csv'.format(args.exp, split))\n",
    "                )\n",
    "                print(result)\n",
    "            # Same as test - assuming that it has no labels\n",
    "            else:\n",
    "                hm.predict(\n",
    "                    get_tuple(split, bs=args.batch_size,\n",
    "                            shuffle=False, drop_last=False),\n",
    "                    dump=os.path.join(args.output, '{}_{}.csv'.format(args.exp, split))\n",
    "                )\n",
    "                \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "considerable-mainland",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-24T08:09:06.733544Z",
     "iopub.status.busy": "2021-06-24T08:09:06.729057Z",
     "iopub.status.idle": "2021-06-24T08:09:07.524229Z",
     "shell.execute_reply": "2021-06-24T08:09:07.523628Z",
     "shell.execute_reply.started": "2021-06-23T19:34:17.692182Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 2.290153,
     "end_time": "2021-06-24T08:09:07.524382",
     "exception": false,
     "start_time": "2021-06-24T08:09:05.234229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp ../input/testjsonl/example.jsonl ../vilio/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atlantic-trout",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-24T08:09:10.355402Z",
     "iopub.status.busy": "2021-06-24T08:09:10.349993Z",
     "iopub.status.idle": "2021-06-24T08:11:46.762918Z",
     "shell.execute_reply": "2021-06-24T08:11:46.762299Z",
     "shell.execute_reply.started": "2021-06-23T19:34:18.372377Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 157.924375,
     "end_time": "2021-06-24T08:11:46.763093",
     "exception": false,
     "start_time": "2021-06-24T08:09:08.838718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-24 08:09:13.505889: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64:/opt/conda/lib\r\n",
      "2021-06-24 08:09:13.506526: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n",
      "comet_ml is installed but `COMET_API_KEY` is not set.\r\n",
      "Downloading: 100%|██████████████████████████████| 625/625 [00:00<00:00, 400kB/s]\r\n",
      "Downloading: 100%|████████████████████████████| 213k/213k [00:00<00:00, 652kB/s]\r\n",
      "Downloading: 100%|█████████████████████████| 1.34G/1.34G [01:53<00:00, 11.8MB/s]\r\n",
      "UNEXPECTED:  []\r\n",
      "MISSING:  ['bert.img_embeddings.img_linear.weight', 'bert.img_embeddings.img_linear.bias', 'bert.img_embeddings.img_layer_norm.weight', 'bert.img_embeddings.img_layer_norm.bias', 'bert.img_embeddings.pos_layer_norm.weight', 'bert.img_embeddings.pos_layer_norm.bias', 'bert.img_embeddings.pos_linear.weight', 'bert.img_embeddings.pos_linear.bias', 'bert.img_embeddings.LayerNorm.weight', 'bert.img_embeddings.LayerNorm.bias']\r\n",
      "ERRORS:  []\r\n",
      "REINITING:  Linear(in_features=1024, out_features=2048, bias=True)\r\n",
      "REINITING:  GeLU()\r\n",
      "REINITING:  LayerNorm((2048,), eps=1e-12, elementwise_affine=True)\r\n",
      "REINITING:  Linear(in_features=2048, out_features=2, bias=True)\r\n",
      "REINITING:  Sequential(\r\n",
      "  (0): Linear(in_features=1024, out_features=2048, bias=True)\r\n",
      "  (1): GeLU()\r\n",
      "  (2): LayerNorm((2048,), eps=1e-12, elementwise_affine=True)\r\n",
      "  (3): Linear(in_features=2048, out_features=2, bias=True)\r\n",
      ")\r\n",
      "Load model from ../input/viliou36/LASTtrain.pth\r\n",
      "Load 1 data from split(s) example.\r\n",
      "Start to load Faster-RCNN detected objects from data/HM_img.tsv\r\n",
      "Loaded 1 images in file data/HM_img.tsv in 0 seconds.\r\n",
      "Use 1 data in torch dataset\r\n",
      "\r\n",
      "<class 'pandas.core.frame.DataFrame'>\r\n",
      "RangeIndex: 1 entries, 0 to 0\r\n",
      "Data columns (total 3 columns):\r\n",
      " #   Column  Non-Null Count  Dtype  \r\n",
      "---  ------  --------------  -----  \r\n",
      " 0   id      1 non-null      int64  \r\n",
      " 1   proba   1 non-null      float64\r\n",
      " 2   label   1 non-null      int64  \r\n",
      "dtypes: float64(1), int64(2)\r\n",
      "memory usage: 152.0 bytes\r\n",
      "None\r\n"
     ]
    }
   ],
   "source": [
    "!cd ../vilio; python hm_inf.py --seed 42 --model U \\\n",
    "--test example --batchSize 1 --tr bert-large-cased --tsv \\\n",
    "--num_features 36 --num_pos 6 --exp U36 --loadfin ../input/viliou36/LASTtrain.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "scheduled-shopping",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-24T08:11:50.341098Z",
     "iopub.status.busy": "2021-06-24T08:11:50.339835Z",
     "iopub.status.idle": "2021-06-24T08:11:51.190296Z",
     "shell.execute_reply": "2021-06-24T08:11:51.189700Z",
     "shell.execute_reply.started": "2021-06-23T19:37:06.202086Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 2.73387,
     "end_time": "2021-06-24T08:11:51.190481",
     "exception": false,
     "start_time": "2021-06-24T08:11:48.456611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,proba,label\r\n",
      "10002,-9.773689270019531,0\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../vilio/data/U36_example.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-benefit",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 1.751099,
     "end_time": "2021-06-24T08:11:54.660959",
     "exception": false,
     "start_time": "2021-06-24T08:11:52.909860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 ('pyenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 918.713758,
   "end_time": "2021-06-24T08:11:56.986946",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-24T07:56:38.273188",
   "version": "2.3.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5db0b11a2c28e650914bcadf765ce81163110bd05441a302796e68891d33648"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
